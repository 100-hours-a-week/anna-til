# 🧴 딥다이브 - SciPy를 활용한 기본 통계 분석  

## 날짜: 2025-02-14 📅

## 📌 SciPy를 활용한 통계 분석이 데이터 해석에 주는 도움 ✨  

SciPy는 강력한 수학 및 과학 계산 기능을 제공하며, 특히 **통계 분석**에서 유용하다.  
통계 분석을 통해 데이터의 **중심 경향(평균, 중앙값, 최빈값), 분포 특성(정규성 검정), 변수 간 관계(상관 분석, 회귀 분석)** 등을 파악할 수 있다.  

---

### **1. 데이터의 중심 경향 및 분포 분석**  

- **평균(mean)**: 데이터의 중심값  
- **중앙값(median)**: 데이터의 중앙에 위치한 값  
- **최빈값(mode)**: 가장 많이 등장하는 값  
- **표준 편차(standard deviation)**: 데이터의 퍼짐 정도  


### **2. 데이터의 정규성 검정**
정규 분포 여부를 확인하는 것은 가설 검정 및 확률 계산에 중요하다.

```python
stat, p_value = stats.shapiro(data)
print(f"Shapiro-Wilk Test p-value: {p_value}")
✅ 핵심 정리

p-value < 0.05 → 데이터가 정규 분포를 따르지 않음
p-value ≥ 0.05 → 정규 분포 가능성이 높음
```

### ** 3. 가설 검정 (t-검정)
두 그룹 간 평균 차이가 유의미한지 판단하는 데 사용된다.

```python

group1 = np.array([12, 14, 15, 16, 17, 18, 19])
group2 = np.array([22, 24, 25, 26, 27, 28, 29])

t_stat, p_val = stats.ttest_ind(group1, group2)
print(f"t-검정 결과: t-statistic={t_stat}, p-value={p_val}")
```
✅ 핵심 정리

p-value < 0.05 → 두 그룹 간 차이가 통계적으로 유의미함
p-value ≥ 0.05 → 차이가 우연일 가능성이 높음

### **4. 상관 분석 (Correlation Analysis)**
두 변수 간 관계를 분석할 때 상관 계수(Correlation Coefficient) 를 활용한다.

```python
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

corr_coef, p_value = stats.pearsonr(x, y)
print(f"피어슨 상관 계수: {corr_coef}, p-value: {p_value}")
```
✅ 핵심 정리

상관 계수(r) 값
1에 가까울수록 → 강한 양의 상관관계
-1에 가까울수록 → 강한 음의 상관관계
0에 가까울수록 → 상관관계가 거의 없음

### **5. 회귀 분석 (Regression Analysis)**
변수 간의 관계를 모델링할 때 선형 회귀(Linear Regression) 를 활용한다.

```python
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
print(f"회귀식: y = {slope} * x + {intercept}")
print(f"결정 계수(R^2): {r_value**2}")
```
✅ 핵심 정리

결정 계수(R²) 값
1에 가까울수록 → 회귀 모델이 데이터를 잘 설명함
0에 가까울수록 → 회귀 모델의 설명력이 낮음
### **6. 확률 분포 모델링**
SciPy를 활용하면 다양한 확률 분포(Probability Distribution) 를 모델링할 수 있다.

```python

prob = stats.norm.cdf(1.5, loc=0, scale=1)  # 평균 0, 표준 편차 1인 정규 분포에서 1.5 이하일 확률
print(f"1.5 이하일 확률: {prob}")
```
✅ 핵심 정리

stats.norm.cdf()를 활용하면 특정 값 이하의 확률을 쉽게 계산할 수 있다.
확률 분포 모델링은 데이터 분석과 머신러닝에서 중요한 개념이다.

### 오늘의 회고 📝
SciPy의 stats 모듈을 활용하여 기본적인 통계 분석(평균, 분산, 표준 편차, 최빈값 등) 을 수행할 수 있었다.
가설 검정, 상관 분석, 회귀 분석 등을 실습하면서 데이터 해석의 중요성을 다시금 깨달았다.
정규 분포 모델링과 확률 계산을 통해 데이터 분석에서 확률 분포가 어떻게 활용되는지 이해할 수 있었다.